import os
import json
import traceback
import pandas as pd
from dotenv import load_dotenv
from src.mcqgenerator.utils import read_file, get_table_data
from src.mcqgenerator.logger import logging

from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableSequence
from langchain_core.output_parsers import StrOutputParser

# Load environment variables from the .env file
load_dotenv()

# Access the environment variables just like you would with os.environ
key = os.getenv("OPENAI_API_KEY")
print("KEY IS : ", key)

llm = ChatOpenAI(openai_api_key=key, model_name="gpt-3.5-turbo", temperature=0.7)

# Quiz generation prompt
quiz_template = """
Text: {text}
You are an expert MCQ maker. Given the above text, it is your job to create a quiz of {number} multiple choice questions for {subject} students in {tone} tone. Make sure the questions are not repeated and check all the questions to conform to the text as well.
Make sure to format your response like RESPONSE_JSON below and use it as a guide.
Ensure to make {number} MCQs
### RESPONSE_JSON
{response_json}
"""

quiz_generation_prompt = PromptTemplate(
    input_variables=["text", "number", "subject", "tone", "response_json"],
    template=quiz_template
)

# Quiz evaluation prompt
evaluation_template = """
You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students.
You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. If the quiz is not up to the cognitive and analytical abilities of the students,
update the quiz questions which need to be changed and change the tone such that it perfectly fits the student's abilities.
Quiz_MCQs: {quiz}
Check from an expert English Writer of the above quiz:
"""

quiz_evaluation_prompt = PromptTemplate(
    input_variables=["subject", "quiz"],
    template=evaluation_template
)

# Create the chains
quiz_chain = llm | quiz_generation_prompt | StrOutputParser()
review_chain = llm | quiz_evaluation_prompt | StrOutputParser()

# Combine the chains using RunnableSequence
generate_evaluate_chain = RunnableSequence(steps=[quiz_chain, review_chain])

# Define a function to run the combined chains
def run_chain(text, number, subject, tone, response_json):
    result = generate_evaluate_chain.invoke({
        "text": text,
        "number": number,
        "subject": subject,
        "tone": tone,
        "response_json": response_json
    })
    return result

# Example usage
if __name__ == "__main__":
    try:
        # Replace with your actual inputs
        example_text = "Sample text for quiz generation."
        example_number = 5
        example_subject = "Mathematics"
        example_tone = "formal"
        example_response_json = "{}"  # Replace with actual JSON structure if needed

        result = run_chain(example_text, example_number, example_subject, example_tone, example_response_json)
        print(result)
    except Exception as e:
        print("An error occurred:", str(e))
        traceback.print_exc()



# generate_evaluate_chain = SequentialChain(
#     chains=[quiz_chain, review_chain],
#     input_variables=["text", "number", "subject", "tone", "response_json"],
#     output_variables=["quiz", "review"],
#     verbose=True
# )




# import os
# import json
# import traceback
# import pandas as pd
# from dotenv import load_dotenv
# from src.mcqgenerator.utils import read_file, get_table_data
# from src.mcqgenerator.logger import logging

# # Importing necessary packages from LangChain
# # from langchain.chat_models import ChatOpenAI
# from langchain_community.chat_models import ChatOpenAI
# from langchain.prompts import PromptTemplate
# from langchain.chains import LLMChain, SequentialChain

# # Load environment variables from the .env file
# load_dotenv()

# # Access the environment variables just like you would with os.environ
# key = os.getenv("OPENAI_API_KEY")

# llm = ChatOpenAI(openai_api_key=key, model_name="gpt-3.5-turbo", temperature=0.7)

# template = """
# Text: {text}
# You are an expert MCQ maker. Given the above text, it is your job to create a quiz of {number} multiple choice questions for {subject} students in {tone} tone. Make sure the questions are not repeated and check all the questions to conform to the text as well.
# Make sure to format your response like RESPONSE_JSON below and use it as a guide.
# Ensure to make {number} MCQs
# ### RESPONSE_JSON
# {response_json}
# """

# quiz_generation_prompt = PromptTemplate(
#     input_variables=["text", "number", "subject", "tone", "response_json"],
#     template=template
# )

# quiz_chain = LLMChain(
#     llm=llm,
#     prompt=quiz_generation_prompt,
#     output_key="quiz",
#     verbose=True
# )

# template2 = """
# You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students.
# You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. If the quiz is not up to the cognitive and analytical abilities of the students,
# update the quiz questions which need to be changed and change the tone such that it perfectly fits the student's abilities.
# Quiz_MCQs: {quiz}
# Check from an expert English Writer of the above quiz:
# """

# quiz_evaluation_prompt = PromptTemplate(
#     input_variables=["subject", "quiz"],
#     template=template2
# )

# review_chain = LLMChain(
#     llm=llm,
#     prompt=quiz_evaluation_prompt,
#     output_key="review",
#     verbose=True
# )

# # This is an Overall Chain where we run the two chains in Sequence
# generate_evaluate_chain = SequentialChain(
#     chains=[quiz_chain, review_chain],
#     input_variables=["text", "number", "subject", "tone", "response_json"],
#     output_variables=["quiz", "review"],
#     verbose=True
# )
